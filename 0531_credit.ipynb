{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0531_변수만들기_혜린.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "XFRwzuBQb20S",
        "tWddbz6SfPRs",
        "IycM8KyvcGBG",
        "tApqPLoNforH",
        "K9XWRqkfqarN",
        "M-NTcwkLvSEZ",
        "ZmX_HqZsxIEo",
        "BMRG5QQ9xVA5",
        "ygBOo-5A0W7i"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seryeongi/pjt_credit/blob/master/0531_credit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDV9bGf6ZawO",
        "outputId": "511c92a2-f426-4bf7-efc4-37b8ea8d8123"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRTHzow5Z9Lt",
        "outputId": "072548b7-de5b-483a-db8c-1d5246e73da2"
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n",
            "\r\u001b[K     |████                            | 10kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 40kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 71kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.19.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.1.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjvi8lcMaTDU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c4e64f8-c383-4b04-e81f-f71c7e5d332e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "import re\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RandomizedSearchCV \n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.utils import shuffle\n",
        "from scipy.special import erfc\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, RandomForestRegressor, VotingRegressor\n",
        "\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "\n",
        "import warnings\n",
        "\n",
        "from category_encoders.ordinal import OrdinalEncoder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxNQGDfmaaXz"
      },
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/creditcard/open/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/creditcard/open/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsWQ7J2zzmQb"
      },
      "source": [
        "## 기본 변환"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFRwzuBQb20S"
      },
      "source": [
        "#### 1) 0, 1 변환"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWddbz6SfPRs"
      },
      "source": [
        "#### 2) 수 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o28BxZnLaaTs"
      },
      "source": [
        "# 음수 -> 양수 변환\n",
        "\n",
        "train.DAYS_BIRTH = -train.DAYS_BIRTH\n",
        "test.DAYS_BIRTH = -test.DAYS_BIRTH\n",
        "\n",
        "train.DAYS_EMPLOYED = -train.DAYS_EMPLOYED\n",
        "test.DAYS_EMPLOYED = -test.DAYS_EMPLOYED\n",
        "\n",
        "train.begin_month = -train.begin_month\n",
        "test.begin_month = -test.begin_month"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7eXyyutaaQt"
      },
      "source": [
        "# 365243 인 값 0으로 바꾸기\n",
        "\n",
        "train.DAYS_EMPLOYED = train.DAYS_EMPLOYED.replace([-365243],[0])\n",
        "test.DAYS_EMPLOYED = test.DAYS_EMPLOYED.replace([-365243],[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7OF1ayKfN03"
      },
      "source": [
        "# 360으로 나눠서 나이, 일한 년수 계산\n",
        "\n",
        "train['EMPLOYED']= train.DAYS_EMPLOYED.apply(lambda x: abs(x/360) )\n",
        "train['age']= train.DAYS_BIRTH.apply(lambda x: abs(x/360) ).astype(int)\n",
        "train['begin_month']= train.begin_month.apply(lambda x: abs(x) ).astype(int)\n",
        "\n",
        "test['EMPLOYED']= test.DAYS_EMPLOYED.apply(lambda x: abs(x/360) )\n",
        "test['age']= test.DAYS_BIRTH.apply(lambda x: abs(x/360) ).astype(int)\n",
        "test['begin_month']= test.begin_month.apply(lambda x: abs(x) ).astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IycM8KyvcGBG"
      },
      "source": [
        "#### 3) 로그변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CYBox1aaaN_"
      },
      "source": [
        "tr_it=train['income_total']\n",
        "tr_it_log = np.log1p(tr_it)\n",
        "train['income_total']= tr_it_log\n",
        "te_it=test['income_total']\n",
        "te_it_log = np.log1p(te_it)\n",
        "test['income_total']= te_it_log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFxg08XvaaLg"
      },
      "source": [
        "train['EMPLOYED']= np.log1p(train['EMPLOYED'])\n",
        "test['EMPLOYED']= np.log1p(test['EMPLOYED'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij0p241Vfe5h"
      },
      "source": [
        "#### 4) child_num, family_size 관련 컬럼 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hes4ZTUYYhsb",
        "outputId": "cb845639-31ee-4e31-a34e-b685af391f71"
      },
      "source": [
        "train['child_num'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     18340\n",
              "1      5386\n",
              "2      2362\n",
              "3       306\n",
              "4        47\n",
              "5        10\n",
              "14        3\n",
              "7         2\n",
              "19        1\n",
              "Name: child_num, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fogp3bv5ckm4"
      },
      "source": [
        "# child_num이 14, 19인 행 지우기\n",
        "\n",
        "idx_child_drop = train[(train['child_num'] == 14)|(train['child_num'] == 19)].index\n",
        "train = train.drop(idx_child_drop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCNkwx6Eckk3"
      },
      "source": [
        "# child_num이 family_size보다 큰 행도 지우기\n",
        "\n",
        "idx_child_drop2 = train[train['family_size'] < train['child_num']].index\n",
        "train = train.drop(idx_child_drop2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71eukZr7ckgI"
      },
      "source": [
        "train['cf_ratio'] = train['child_num'] / train['family_size']\n",
        "test['cf_ratio'] = test['child_num'] / test['family_size']\n",
        "\n",
        "# train['if_ratio'] = train['income_total'] / train['family_size']\n",
        "# test['if_ratio'] = test['income_total'] / test['family_size']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MT4wyjSoXu9g",
        "outputId": "21cff04b-59a3-46cf-b852-98ba0729c9de"
      },
      "source": [
        "train['family_size'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0    14106\n",
              "1.0     5108\n",
              "3.0     4632\n",
              "4.0     2260\n",
              "5.0      291\n",
              "6.0       44\n",
              "7.0        9\n",
              "9.0        2\n",
              "Name: family_size, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL3-ugvhYMam"
      },
      "source": [
        "# family_size > 7 인 것도 지우기\n",
        "train = train[(train['family_size']<=7)]\n",
        "train = train.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tApqPLoNforH"
      },
      "source": [
        "#### 5) 결측치 채우기 - unemployed 만들고 nan 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n__9qpcEckin"
      },
      "source": [
        "def unemployed(data):\n",
        "  data.loc[(data['DAYS_EMPLOYED'] == 0), 'occyp_type'] = 'unemployed'\n",
        "\n",
        "unemployed(train)\n",
        "unemployed(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx_CGoWFg8Hb"
      },
      "source": [
        "train.fillna('Nan', inplace=True)\n",
        "test.fillna('Nan',inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "HfvF5bKrj1Bn",
        "outputId": "e04cd3a8-9433-4dc7-c666-3e58888ead68"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>gender</th>\n",
              "      <th>car</th>\n",
              "      <th>reality</th>\n",
              "      <th>child_num</th>\n",
              "      <th>income_total</th>\n",
              "      <th>income_type</th>\n",
              "      <th>edu_type</th>\n",
              "      <th>family_type</th>\n",
              "      <th>house_type</th>\n",
              "      <th>DAYS_BIRTH</th>\n",
              "      <th>DAYS_EMPLOYED</th>\n",
              "      <th>FLAG_MOBIL</th>\n",
              "      <th>work_phone</th>\n",
              "      <th>phone</th>\n",
              "      <th>email</th>\n",
              "      <th>occyp_type</th>\n",
              "      <th>family_size</th>\n",
              "      <th>begin_month</th>\n",
              "      <th>credit</th>\n",
              "      <th>EMPLOYED</th>\n",
              "      <th>age</th>\n",
              "      <th>cf_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>12.218500</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>Municipal apartment</td>\n",
              "      <td>13899</td>\n",
              "      <td>4709</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Nan</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.644795</td>\n",
              "      <td>38</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>1</td>\n",
              "      <td>12.419170</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>11380</td>\n",
              "      <td>1540</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Laborers</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.663505</td>\n",
              "      <td>31</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>13.017005</td>\n",
              "      <td>Working</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>19087</td>\n",
              "      <td>4434</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Managers</td>\n",
              "      <td>2.0</td>\n",
              "      <td>22</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.589016</td>\n",
              "      <td>53</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>12.218500</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>15088</td>\n",
              "      <td>2092</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Sales staff</td>\n",
              "      <td>2.0</td>\n",
              "      <td>37</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.918555</td>\n",
              "      <td>41</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>F</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>11.967187</td>\n",
              "      <td>State servant</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>15037</td>\n",
              "      <td>2105</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Managers</td>\n",
              "      <td>2.0</td>\n",
              "      <td>26</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.923843</td>\n",
              "      <td>41</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index gender car reality  ...  credit  EMPLOYED age  cf_ratio\n",
              "0      0      F   N       N  ...     1.0  2.644795  38  0.000000\n",
              "1      1      F   N       Y  ...     1.0  1.663505  31  0.333333\n",
              "2      2      M   Y       Y  ...     2.0  2.589016  53  0.000000\n",
              "3      3      F   N       Y  ...     0.0  1.918555  41  0.000000\n",
              "4      4      F   Y       Y  ...     2.0  1.923843  41  0.000000\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWjwg14szzF0"
      },
      "source": [
        "#### 명목형 변수 처리 - OrdinalEncoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdKlLGkBm0HY"
      },
      "source": [
        "encoder = OrdinalEncoder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD4-JU9cmwgM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63bd5c66-fb57-42fa-af84-a58a2a43619a"
      },
      "source": [
        "cate_feature = train.dtypes[train.dtypes == 'object'].index.tolist()\n",
        "print(len(cate_feature))\n",
        "print(train.dtypes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n",
            "index              int64\n",
            "gender            object\n",
            "car               object\n",
            "reality           object\n",
            "child_num          int64\n",
            "income_total     float64\n",
            "income_type       object\n",
            "edu_type          object\n",
            "family_type       object\n",
            "house_type        object\n",
            "DAYS_BIRTH         int64\n",
            "DAYS_EMPLOYED      int64\n",
            "FLAG_MOBIL         int64\n",
            "work_phone         int64\n",
            "phone              int64\n",
            "email              int64\n",
            "occyp_type        object\n",
            "family_size      float64\n",
            "begin_month        int64\n",
            "credit           float64\n",
            "EMPLOYED         float64\n",
            "age                int64\n",
            "cf_ratio         float64\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YsPFkgKm2Ew",
        "outputId": "22c3724f-6590-4cc5-ba03-fe8742f5f430"
      },
      "source": [
        "train[cate_feature] = encoder.fit_transform(train[cate_feature],train['credit'])\n",
        "test[cate_feature] = encoder.fit_transform(test[cate_feature])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqX2zuShdGFW"
      },
      "source": [
        "train = train.drop(['index', 'FLAG_MOBIL', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'child_num','cf_ratio'], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "EqSTQo1-u_1S",
        "outputId": "ecaccaae-14b0-4ace-ebae-4168096eef28"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>car</th>\n",
              "      <th>reality</th>\n",
              "      <th>income_total</th>\n",
              "      <th>income_type</th>\n",
              "      <th>edu_type</th>\n",
              "      <th>family_type</th>\n",
              "      <th>house_type</th>\n",
              "      <th>work_phone</th>\n",
              "      <th>phone</th>\n",
              "      <th>email</th>\n",
              "      <th>occyp_type</th>\n",
              "      <th>family_size</th>\n",
              "      <th>begin_month</th>\n",
              "      <th>credit</th>\n",
              "      <th>EMPLOYED</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12.218500</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.644795</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>12.419170</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.663505</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>13.017005</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>22</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.589016</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>12.218500</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>37</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.918555</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>11.967187</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>26</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.923843</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender  car  reality  income_total  ...  begin_month  credit  EMPLOYED  age\n",
              "0       1    1        1     12.218500  ...            6     1.0  2.644795   38\n",
              "1       1    1        2     12.419170  ...            5     1.0  1.663505   31\n",
              "2       2    2        2     13.017005  ...           22     2.0  2.589016   53\n",
              "3       1    1        2     12.218500  ...           37     0.0  1.918555   41\n",
              "4       1    2        2     11.967187  ...           26     2.0  1.923843   41\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljGdMqOrf3V1"
      },
      "source": [
        "# 간단한 autoencoder 모델 구현"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StLLt7srN9Qf"
      },
      "source": [
        "AutoEncoder + NN 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfbnmL4fRSY6"
      },
      "source": [
        "* 입출력이 같은 구조\n",
        "* input data를 잘 복원한다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwX5O8umSivv"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKMg7TKVSuHT"
      },
      "source": [
        "인코더 작성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_MTFNcEN3p6"
      },
      "source": [
        "input_dim = Input(shape=(16,)) # 입력 채널 수: 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuPMYa5eS49Q"
      },
      "source": [
        "encoder1 = Dense(8, activation = 'relu')(input_dim)\n",
        "encoder2 = Dense(3, activation = 'relu')(encoder1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSAvsw5MS5Ut"
      },
      "source": [
        "decoder1 = Dense(8, activation='relu')(encoder2)\n",
        "decoder2 = Dense(16, activation='relu')(decoder1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUjRnOVaTbJ_"
      },
      "source": [
        "모델 작성 및 컴파일"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7vVj-A_S5eB"
      },
      "source": [
        "autoencoder = Model(inputs = input_dim, outputs = decoder2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry3OGFz6S5mo"
      },
      "source": [
        "autoencoder.compile(optimizer = 'adam', loss = 'binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRUrmqjKhDAJ"
      },
      "source": [
        "train_y = train['credit']\n",
        "train_x = train.drop(\"credit\", axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2vsooHfCMik"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(train_x, train_y,\n",
        "                 stratify = train_y, \n",
        "                 test_size = 0.2,\n",
        "                 random_state = 10086\n",
        "                 )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQdxa_TuTnJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94a1cc0f-4687-4c34-ddaf-09e0b38cc6db"
      },
      "source": [
        "autoencoder.fit(x_train, x_train, batch_size= 32, shuffle= True, validation_data = (x_test,x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "662/662 [==============================] - 2s 2ms/step - loss: 65.9169 - val_loss: 60.6431\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3a68394890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQgWXKfD_MPz"
      },
      "source": [
        "딥러닝 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVP3segziTWM"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpNteKQq8pPw"
      },
      "source": [
        "tf.data를 사용해 입력 파이프라인 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig0INHE0B1Se"
      },
      "source": [
        "train.fillna('Nan',inplace=True)\n",
        "test.fillna('Nan',inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOr8ZNOABAV3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6875b9bb-a968-4a8e-ab96-d3e3dc4524ce"
      },
      "source": [
        "# 딥러닝 모델 구현 위해 train dataset으로 train, test, val 나누기\n",
        "temp_train, temp_test = train_test_split(train, test_size = 0.2)\n",
        "temp_train, temp_val = train_test_split(train, test_size = 0.2)\n",
        "print(len(temp_train), 'train examples')\n",
        "print(len(temp_val), 'validation examples')\n",
        "print(len(temp_test), 'test examples')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21165 train examples\n",
            "5292 validation examples\n",
            "5292 test examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3s8U-im9j-9"
      },
      "source": [
        "d_train = train.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOy08Q0a_Wsi"
      },
      "source": [
        "def df_to_dataset(d_train,shuffle=True,batch_size = 32):\n",
        "  labels = d_train.pop('credit')\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(d_train), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size = len(d_train))\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(batch_size)\n",
        "    return ds\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGCAyD5i8omD"
      },
      "source": [
        "batch_size = 5\n",
        "train_ds = df_to_dataset(temp_train, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk_bunNF8ojV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7b360a9-a295-440f-928a-f65e36c9fd01"
      },
      "source": [
        "[(train_features, label_batch)] = train_ds.take(1)\n",
        "print('Every feature:', list(train_features.keys()))\n",
        "print('A batch of targets:', label_batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Every feature: ['index', 'gender', 'car', 'reality', 'child_num', 'income_total', 'income_type', 'edu_type', 'family_type', 'house_type', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'FLAG_MOBIL', 'work_phone', 'phone', 'email', 'occyp_type', 'family_size', 'begin_month']\n",
            "A batch of targets: tf.Tensor([2. 2. 2. 2. 2.], shape=(5,), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzEg3lAhCdhr"
      },
      "source": [
        "전처리 레이어의 사용 시연"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxm30UWJCgad"
      },
      "source": [
        "1. 숫자 열"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sybe4D8-8ogf"
      },
      "source": [
        "def get_normalization_layer(name, dataset):\n",
        "  normalizer = preprocessing.Normalization()\n",
        "  feature_ds = dataset.map(lambda x, y: x[name])\n",
        "  normalizer.adapt(feature_ds)\n",
        "  return normalizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwImv1ch8odJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83a2bd0-b576-443b-b08b-3d55d00afa16"
      },
      "source": [
        "income_total_col = train_features['income_total']\n",
        "layer = get_normalization_layer('income_total', train_ds)\n",
        "layer(income_total_col)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
              "array([[ 0.36945453],\n",
              "       [-0.07058038],\n",
              "       [ 1.2495244 ],\n",
              "       [ 0.14943708],\n",
              "       [-0.5106153 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTds9ocbDNWA"
      },
      "source": [
        "숫자 특성이 많은 경우, 먼저 숫자 특성을 연결하고 단일 normalization 레이어를 사용하는 것이 더 효율적"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkmkIv5dDSft"
      },
      "source": [
        "2. 범주 열"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xby9-hvN8oaI"
      },
      "source": [
        "def get_category_encoding_layer(name, dataset, dtype, max_tokens = None):\n",
        "  if dtype == 'string':\n",
        "    index = preprocessing.StringLookup(max_tokens=max_tokens)\n",
        "  else:\n",
        "    index = preprocessing.IntegerLookup(max_values = max_tokens)\n",
        "  feature_ds = dataset.map(lambda x, y: x[name])\n",
        "  index.adapt(feature_ds)\n",
        "  encoder = preprocessing.CategoryEncoding(max_tokens = index.vocabulary_size())\n",
        "  feature_ds = feature_ds.map(index)\n",
        "  encoder.adapt(feature_ds)\n",
        "  return lambda feature: encoder(index(feature))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGUBr1pJHTpO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e59010cd-890d-4736-eca2-c913015461f9"
      },
      "source": [
        "gender_col = train_features['gender']\n",
        "layer = get_category_encoding_layer('gender', train_ds, 'string')\n",
        "layer(gender_col)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:max_tokens is deprecated, please use num_tokens instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
              "array([[0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q018Xc9QDdVJ"
      },
      "source": [
        "사용할 열 선택 - 열 몇개만 이용해서 구현  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHf-Pg8t8oLB"
      },
      "source": [
        "batch_size = 256\n",
        "train_ds = df_to_dataset(temp_train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(temp_val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(temp_test, shuffle=False, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lttfCcvSHzrc"
      },
      "source": [
        "all_inputs = []\n",
        "encoded_features = []\n",
        "\n",
        "# Numeric features.\n",
        "for header in ['income_total', 'DAYS_BIRTH']:\n",
        "  numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
        "  normalization_layer = get_normalization_layer(header, train_ds)\n",
        "  encoded_numeric_col = normalization_layer(numeric_col)\n",
        "  all_inputs.append(numeric_col)\n",
        "  encoded_features.append(encoded_numeric_col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoeXQNemIfTN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "57f7677c-62cc-4be3-9086-a08f373df07c"
      },
      "source": [
        "# Categorical features encoded as integers.\n",
        "fam_col = tf.keras.Input(shape=(1,), name='family_size', dtype='int64')\n",
        "encoding_layer = get_category_encoding_layer('family_size', train_ds, dtype='int64',\n",
        "                                             max_tokens=5)\n",
        "encoded_fam_col = encoding_layer(fam_col)\n",
        "all_inputs.append(fam_col)\n",
        "encoded_features.append(encoded_fam_col)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:max_values is deprecated, use max_tokens instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-21c9b45b0005>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mage_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'family_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m encoding_layer = get_category_encoding_layer('family_size', train_ds, dtype='int64',\n\u001b[0;32m----> 4\u001b[0;31m                                              max_tokens=5)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mencoded_age_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mall_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-2b31f8113eff>\u001b[0m in \u001b[0;36mget_category_encoding_layer\u001b[0;34m(name, dataset, dtype, max_tokens)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegerLookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mfeature_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategoryEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mfeature_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/preprocessing/index_lookup.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, reset_state)\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreset_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"IndexLookup does not support streaming adapts.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndexLookup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, batch_size, steps, reset_state)\u001b[0m\n\u001b[1;32m    329\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_accumulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combiner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     super(CombinerPreprocessingLayer, self).adapt(\n\u001b[0;32m--> 331\u001b[0;31m         data, batch_size=batch_size, steps=steps, reset_state=reset_state)\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   def _add_state_variable(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, batch_size, steps, reset_state)\u001b[0m\n\u001b[1;32m    243\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_adapted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36mfinalize_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfinalize_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_accumulator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_accumulator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_eagerly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36m_set_accumulator\u001b[0;34m(self, accumulator)\u001b[0m\n\u001b[1;32m    384\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_set_accumulator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccumulator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combiner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccumulator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_state_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_accumulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Reset accumulator from adapt.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/preprocessing/index_lookup.py\u001b[0m in \u001b[0;36m_set_state_variables\u001b[0;34m(self, updates)\u001b[0m\n\u001b[1;32m    594\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_set_state_variables() must be called after build().\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     self.set_vocabulary(\n\u001b[0;32m--> 596\u001b[0;31m         updates[_VOCAB_NAME], idf_weights=updates[_IDF_WEIGHTS_NAME])\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/preprocessing/integer_lookup.py\u001b[0m in \u001b[0;36mset_vocabulary\u001b[0;34m(self, vocabulary, idf_weights)\u001b[0m\n\u001b[1;32m    332\u001b[0m       \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocabulary_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midf_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midf_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/preprocessing/index_lookup.py\u001b[0m in \u001b[0;36mset_vocabulary\u001b[0;34m(self, vocabulary, idf_weights)\u001b[0m\n\u001b[1;32m    562\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_table_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_table_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_token\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_table_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mask_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mask_value\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/preprocessing/table_utils.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, keys, values)\u001b[0m\n\u001b[1;32m     88\u001b[0m                          (len(keys), len(values)))\n\u001b[1;32m     89\u001b[0m     keys = ops.convert_to_tensor_v2_with_dispatch(\n\u001b[0;32m---> 90\u001b[0;31m         keys, dtype=self.table._key_dtype)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m     91\u001b[0m     values = ops.convert_to_tensor_v2_with_dispatch(\n\u001b[1;32m     92\u001b[0m         values, dtype=self.table._value_dtype)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1429\u001b[0m   \"\"\"\n\u001b[1;32m   1430\u001b[0m   return convert_to_tensor_v2(\n\u001b[0;32m-> 1431\u001b[0;31m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[0m\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1439\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    337\u001b[0m                                          as_ref=False):\n\u001b[1;32m    338\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot convert [2.0, 1.0, 3.0] to EagerTensor of dtype int64"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yggcyjwfJAjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0df27dcd-0586-4b9c-bc84-9918a0302df1"
      },
      "source": [
        "# Categorical features encoded as string.\n",
        "categorical_cols = ['gender', 'car', 'reality', 'edu_type']\n",
        "for header in categorical_cols:\n",
        "  categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
        "  encoding_layer = get_category_encoding_layer(header, train_ds, dtype='string',\n",
        "                                               max_tokens=5)\n",
        "  encoded_categorical_col = encoding_layer(categorical_col)\n",
        "  all_inputs.append(categorical_col)\n",
        "  encoded_features.append(encoded_categorical_col)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:max_tokens is deprecated, please use num_tokens instead.\n",
            "WARNING:tensorflow:max_tokens is deprecated, please use num_tokens instead.\n",
            "WARNING:tensorflow:max_tokens is deprecated, please use num_tokens instead.\n",
            "WARNING:tensorflow:max_tokens is deprecated, please use num_tokens instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBRE95nPJXuZ"
      },
      "source": [
        "모델 생성, 컴파일 및 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAhcB7IgJbKe"
      },
      "source": [
        "all_features = tf.keras.layers.concatenate(encoded_features)\n",
        "x = tf.keras.layers.Dense(32, activation=\"relu\")(all_features)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "output = tf.keras.layers.Dense(1)(x)\n",
        "model = tf.keras.Model(all_inputs, output)\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F95MsSBdJd-e"
      },
      "source": [
        "모델 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOb5NZFEJdre",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3342131e-92b8-45c7-a007-926cccfea539"
      },
      "source": [
        "model.fit(train_ds, epochs=10, validation_data=val_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:591: UserWarning: Input dict contained keys ['index', 'child_num', 'income_type', 'family_type', 'house_type', 'DAYS_EMPLOYED', 'FLAG_MOBIL', 'work_phone', 'phone', 'email', 'occyp_type', 'family_size', 'begin_month'] which did not match any model input. They will be ignored by the model.\n",
            "  [n for n in tensors.keys() if n not in ref_input_names])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "83/83 [==============================] - 1s 3ms/step - loss: -0.5333 - accuracy: 0.2169\n",
            "Epoch 2/10\n",
            "83/83 [==============================] - 0s 4ms/step - loss: -2.9164 - accuracy: 0.2386\n",
            "Epoch 3/10\n",
            "83/83 [==============================] - 0s 5ms/step - loss: -6.7825 - accuracy: 0.2386\n",
            "Epoch 4/10\n",
            "83/83 [==============================] - 0s 4ms/step - loss: -12.7383 - accuracy: 0.2386\n",
            "Epoch 5/10\n",
            "83/83 [==============================] - 0s 4ms/step - loss: -21.0026 - accuracy: 0.2386\n",
            "Epoch 6/10\n",
            "83/83 [==============================] - 0s 4ms/step - loss: -31.3734 - accuracy: 0.2386\n",
            "Epoch 7/10\n",
            "83/83 [==============================] - 0s 4ms/step - loss: -43.9206 - accuracy: 0.2386\n",
            "Epoch 8/10\n",
            "83/83 [==============================] - 0s 4ms/step - loss: -58.5396 - accuracy: 0.2386\n",
            "Epoch 9/10\n",
            "83/83 [==============================] - 0s 4ms/step - loss: -74.4941 - accuracy: 0.2386\n",
            "Epoch 10/10\n",
            "83/83 [==============================] - 0s 4ms/step - loss: -93.0193 - accuracy: 0.2386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc7b09c7410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hA51hmAfsvv"
      },
      "source": [
        "명목형 변수 처리 - AutoEncoder  \n",
        "(https://dacon.io/competitions/official/235713/codeshare/2562?page=3&dtype=recent) 참고"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMQtDbafPWVM"
      },
      "source": [
        "결측치 Nan 처리 & 레이블 인코딩\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PWAdkcFP97U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6213842e-4e1e-4c76-898a-549ab91246d2"
      },
      "source": [
        "!pip install kaggler"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggler\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/78/c3d9bb918827037a81429c0f19d0481e516311282d04aff89be21e270eeb/Kaggler-0.9.6.tar.gz (821kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from kaggler) (2.5.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from kaggler) (0.29.23)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.7/dist-packages (from kaggler) (0.1.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (from kaggler) (2.2.3)\n",
            "Collecting ml-metrics\n",
            "  Downloading https://files.pythonhosted.org/packages/c1/e7/c31a2dd37045a0c904bee31c2dbed903d4f125a6ce980b91bae0c961abb8/ml_metrics-0.1.4.tar.gz\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from kaggler) (0.10.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from kaggler) (3.2.2)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from kaggler) (1.5.12)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (from kaggler) (0.90)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (3.3.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (0.36.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (1.12)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (2.5.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (1.15.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (1.34.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (1.1.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (3.1.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (0.12.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (1.19.5)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (1.1.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (1.6.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (3.12.4)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (2.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt->kaggler) (2.5.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt->kaggler) (3.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from hyperopt->kaggler) (4.41.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt->kaggler) (0.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hyperopt->kaggler) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightgbm->kaggler) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ml-metrics->kaggler) (1.1.5)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->kaggler) (0.5.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->kaggler) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->kaggler) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->kaggler) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->kaggler) (2.4.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->kaggler) (2020.12.5)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->kaggler) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->kaggler) (2.23.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->kaggler) (5.0.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->kaggler) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->kaggler) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->kaggler) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->kaggler) (1.30.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->kaggler) (56.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->kaggler) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->kaggler) (0.4.4)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow->kaggler) (1.5.2)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt->kaggler) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm->kaggler) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->ml-metrics->kaggler) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->kaggler) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->kaggler) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->kaggler) (1.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->kaggler) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->kaggler) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->kaggler) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow->kaggler) (4.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->kaggler) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->kaggler) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow->kaggler) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->kaggler) (3.1.0)\n",
            "Building wheels for collected packages: kaggler, ml-metrics\n",
            "  Building wheel for kaggler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggler: filename=Kaggler-0.9.6-cp37-cp37m-linux_x86_64.whl size=2959080 sha256=b22437df30b6d8d8fc6ef1883ddc974fc41881dbbea78d61cf5c1c2147edeafc\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/06/a9/f2a7b621e4c6b0571cec751c462683e7528d4fd0bb51060b4f\n",
            "  Building wheel for ml-metrics (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-metrics: filename=ml_metrics-0.1.4-cp37-none-any.whl size=7850 sha256=7c49128d5c6a6bf04876d4a742078272e9af6664255aacfa2454418aae035973\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/61/2d/776be7b8a4f14c5db48c8e5451451cabc58dc6aa7ee3801163\n",
            "Successfully built kaggler ml-metrics\n",
            "Installing collected packages: ml-metrics, kaggler\n",
            "Successfully installed kaggler-0.9.6 ml-metrics-0.1.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFZbDgixkjZ6"
      },
      "source": [
        "from kaggler.preprocessing import LabelEncoder\n",
        "from kaggler.model import AutoLGB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6fpJ1KzSbq4"
      },
      "source": [
        "index_col = 'index'\n",
        "target_col = 'credit'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssDaiUwwR9zJ"
      },
      "source": [
        "trn = pd.read_csv('/content/drive/MyDrive/creditcard/open/train.csv',index_col=index_col)\n",
        "tst = pd.read_csv('/content/drive/MyDrive/creditcard/open/test.csv',index_col=index_col)\n",
        "sub = pd.read_csv('/content/drive/MyDrive/creditcard/open/sample_submission.csv',index_col=index_col)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZUs6jhAR6Yr"
      },
      "source": [
        "df = pd.concat([trn.drop(target_col, axis = 1),tst],axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXez4Zv8TWph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "130d1731-650b-44af-ce70-eb8c51761798"
      },
      "source": [
        "cate_cols = [x for x in df.columns if df[x].dtype == 'object']\n",
        "num_cols = [x for x in df.columns if x not in cate_cols + [target_col]]\n",
        "feature_cols = num_cols + cate_cols\n",
        "print(len(feature_cols), len(cate_cols), len(num_cols))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18 8 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tccBECrOTlQa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "34f9f5fe-1aff-4d22-d735-57d268e50151"
      },
      "source": [
        "lbe = LabelEncoder(min_obs=10)\n",
        "df[cate_cols] = lbe.fit_transform(df[cate_cols])\n",
        "df[cate_cols].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>car</th>\n",
              "      <th>reality</th>\n",
              "      <th>income_type</th>\n",
              "      <th>edu_type</th>\n",
              "      <th>family_type</th>\n",
              "      <th>house_type</th>\n",
              "      <th>occyp_type</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       gender  car  reality  ...  family_type  house_type  occyp_type\n",
              "index                        ...                                     \n",
              "0           0    0        1  ...            0           2           0\n",
              "1           0    0        0  ...            2           0           1\n",
              "2           1    1        0  ...            0           0           4\n",
              "3           0    0        0  ...            0           0           3\n",
              "4           0    1        0  ...            0           0           4\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KBdp7fSTy16"
      },
      "source": [
        "autoencoder을 명목형 변수에만 해준 후 autolgbm 학습"
      ]
    }
  ]
}